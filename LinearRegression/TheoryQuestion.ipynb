{
 "cells": [
  {
   "cell_type": "raw",
   "id": "a580771f-e65f-4b66-bd27-6a0ebc2913dd",
   "metadata": {},
   "source": [
    "1. What Are the Basic Assumption?(Linear Regression)\n",
    "\n",
    "- Linearity: The relationship between X and the mean of Y is linear.\n",
    "- Homoscedasticity: The variance of residual is the same for any value of X.\n",
    "- Independence: Observations are independent of each other.\n",
    "- Normality: For any fixed value of X, Y is normally distributed.(Normality of residual)\n",
    "- Multicollinearity- should not be multicorelation between features\n",
    "- No autocorelation of error \n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f87f41e8-65ec-488b-bf94-bbd9d096f1b3",
   "metadata": {},
   "source": [
    "Multicollinearity :\n",
    "\n",
    "Multicollineartity means having relation with the features itself If there is relation with independent features itself then it might not provide best solution for dependent features . so In case of small datasets we can drop one feature having higher corelation with another features . But in case of large datasets (says 100+ features) we need to use concept called ridge and lasso regression Especially lasso regression what it does is it perform internally feature selection on some of features making m=0 so it handle multicollineraity"
   ]
  },
  {
   "cell_type": "raw",
   "id": "77caa85b-692d-45d2-9331-a2a9aededf42",
   "metadata": {},
   "source": [
    "Linearity :\n",
    "\n",
    "Here X means the independent features and y is the dependent features.\n",
    "what mean of y denotes is expected or average value of y for given y \n",
    "relation between them is linear it means that the relationship between x and mean of y is given by straight line \n",
    "equation is (Y=β0+ϵβ1X+)\n",
    "where B0 is the intercept \n",
    "and B1 is the weight for each input (or slope)\n",
    "\n",
    "it also means that the change in mean of y is directly proportional to change in x when intercept =0 \n",
    "\n",
    "Graphical Representation :\n",
    "If we plot the graphical representation of linear model straight line should be formed satisfying the \n",
    "equation y=mx+c"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b85596b5-b553-4ad3-bdd5-bd73ed336e3e",
   "metadata": {},
   "source": [
    "Normality of Residual :\n",
    "it means that if we plot the error that is \n",
    "residual = y_test- y_predict \n",
    "if we plot the kde plot for residual it should be normally distributed "
   ]
  },
  {
   "cell_type": "raw",
   "id": "a22baa56-6507-4e53-88cc-7fb22a123b40",
   "metadata": {},
   "source": [
    "Homoscedasticity :(Homo means same scedasticity means scatter)=>Having same scatter  \n",
    "It means that if we plot the scatter plot between y_pred(x-axis) and residual(error-yaxis) then it should \n",
    "have uniform scatter \n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1e03396a-8fc3-438d-b72d-82a4802d2a7d",
   "metadata": {},
   "source": [
    "No autocorelation of error :\n",
    "It means that if we plot all the residual (error )value no pattern should be form \n",
    "there shouldn't be any pattern between residual value \n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "12f07a3e-50dc-4a35-ba0d-6d3332209e45",
   "metadata": {},
   "source": [
    "Advantage of linear Regression :\n",
    "- works exceptionally well for linear data \n",
    "- simple and easy to implement model \n",
    "- solves overfitting using concept likes regularization "
   ]
  },
  {
   "cell_type": "raw",
   "id": "a72690fb-dbad-470a-9375-91dc7d757d74",
   "metadata": {},
   "source": [
    "Disadvantages of linear Regression:\n",
    "- Lot of feature engineering required \n",
    "- Multicollinearity may be the problem \n",
    "- low performence if ouliers are present and prone to noise "
   ]
  },
  {
   "cell_type": "raw",
   "id": "2de573a9-7f8a-4bbe-9199-773b0a4b4e4a",
   "metadata": {},
   "source": [
    "Whether Feature Scaling required ?\n",
    "- Answer is yes (to normally distribute the data ) can be perform using different transformation "
   ]
  },
  {
   "cell_type": "raw",
   "id": "4705fe61-43bb-428d-8975-77d67575dbfe",
   "metadata": {},
   "source": [
    "Impact of missing Values :\n",
    "Doesn't works on missing values "
   ]
  },
  {
   "cell_type": "raw",
   "id": "5f23e33c-93bd-451f-b2ab-1bb2f8fd09e5",
   "metadata": {},
   "source": [
    "Impact of outliers?\n",
    "- Sensitive to outliers "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b390ceac-5cbb-4ecb-a696-d25d508f8766",
   "metadata": {},
   "source": [
    "![](outliers.png)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "fbffc0f5-6bdd-44c5-ae45-96fa397670a2",
   "metadata": {},
   "source": [
    "Types of problem it solves :\n",
    "- Supervised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe2600d-bbad-427a-9844-af92d320539e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
